{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T15:50:19.796263Z",
     "start_time": "2020-11-03T15:50:17.171277Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, math\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(r'E:\\TEST\\ChangeFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T15:50:19.816222Z",
     "start_time": "2020-11-03T15:50:19.798259Z"
    }
   },
   "outputs": [],
   "source": [
    "from recognition.arcface.train import parse_args\n",
    "from recognition.arcface.configs import config, default, update_config\n",
    "from recognition.arcface.build_tensors import get_emb\n",
    "from recognition.arcface.data_generator import DatasetMaker\n",
    "from recognition.arcface.utils import init_vars, histplot_angles, print_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T15:50:19.822195Z",
     "start_time": "2020-11-03T15:50:19.818206Z"
    }
   },
   "outputs": [],
   "source": [
    "update_config(default.network, default.dataset, default.loss, default.initializer, default.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T15:50:18.376Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            self.build()\n",
    "            print_variables(tf.global_variables(), 'global_variables')\n",
    "\n",
    "            conf = tf.ConfigProto()\n",
    "            conf.allow_soft_placement = True\n",
    "            self.sess = tf.Session(config=conf)\n",
    "\n",
    "            # 读取保存变量\n",
    "            restore_path = os.path.join(default.model_dir[0], f'v{default.restore_version[0]}')\n",
    "            loader = tf.train.Saver()\n",
    "            loader.restore(self.sess, restore_path)\n",
    "            print(f'SUCCEED: restore from {restore_path}.')\n",
    "\n",
    "    def debug(self):\n",
    "\n",
    "        angles = self.sess.run(self.train_angles)\n",
    "        histplot_angles([angles.reshape([-1])], ['angles'], 'angles distribution')\n",
    "\n",
    "    def build(self):\n",
    "        dm = DatasetMaker()\n",
    "        train_dataset = dm.read(default.dataset[0], cate='train', aug=False)\n",
    "        train_dataset = train_dataset.shuffle(1000).batch(128)\n",
    "        train_iterator = train_dataset.make_initializable_iterator()\n",
    "        self.train_dataset_init = train_iterator.initializer\n",
    "        train_imgs, self.train_labels = train_iterator.get_next()\n",
    "        train_labels_onehot = tf.one_hot(self.train_labels, config.num_cls)\n",
    "        print(f'SUCCEED: make train dataset from {default.dataset[0]}.')\n",
    "\n",
    "        # 得到语义向量 - 已l2规范化\n",
    "        self.emb, self.l2_cls_weight = get_emb(train_imgs, name='arcface', reuse=False, training=False,\n",
    "                                               keep_prob=1, summary=False)\n",
    "\n",
    "        self.predict, self.acc_num, self.train_angles = self._get_angles(self.emb, self.train_labels)\n",
    "        self.angles1 = self.train_angles * train_labels_onehot\n",
    "        self.angles2 = self.train_angles * (1. - train_labels_onehot)\n",
    "\n",
    "        \"\"\"用于测试的部分\"\"\"\n",
    "        test_dataset = dm.read(default.dataset[0], cate='test', aug=False)\n",
    "        test_dataset = test_dataset.shuffle(1000).batch(128)\n",
    "        test_iterator = test_dataset.make_initializable_iterator()\n",
    "        self.test_dataset_init = test_iterator.initializer\n",
    "        test_imgs, self.test_labels = test_iterator.get_next()\n",
    "        test_labels_onehot = tf.one_hot(self.test_labels, config.num_cls)\n",
    "        print(f'SUCCEED: make test dataset from {default.dataset[0]}.')\n",
    "\n",
    "        # 得到语义向量 - 已l2规范化\n",
    "        emb, _ = get_emb(test_imgs, name='arcface', reuse=True, training=False, keep_prob=1, summary=False)\n",
    "\n",
    "        self.test_predict, self.test_acc_num, test_angles = self._get_angles(emb, self.test_labels)\n",
    "        self.test_angles1 = test_angles * test_labels_onehot\n",
    "        self.test_angles2 = test_angles * (1. - test_labels_onehot)\n",
    "\n",
    "    def _get_angles(self, emb, labels):\n",
    "        cosines = tf.matmul(emb, self.l2_cls_weight)\n",
    "\n",
    "        radians = tf.acos(cosines)\n",
    "        angles = radians * 180 / math.pi\n",
    "\n",
    "        predict = tf.argmax(cosines, axis=1, output_type=labels.dtype)\n",
    "        acc_num = tf.reduce_sum(tf.cast(tf.equal(predict, labels), tf.float32))\n",
    "\n",
    "        return predict, acc_num, angles\n",
    "\n",
    "    def com_all(self):\n",
    "        self._com_all('train')\n",
    "        self._com_all('test')\n",
    "\n",
    "    def _com_all(self, cate='train'):\n",
    "        com_angles1, com_angles2 = [], []\n",
    "        com_acc, com_num = 0, 0\n",
    "        if cate == 'train':\n",
    "            angles1, angles2, acc_num = self.angles1, self.angles2, self.acc_num\n",
    "            dataset_init = self.train_dataset_init\n",
    "        else:\n",
    "            angles1, angles2, acc_num = self.test_angles1, self.test_angles2, self.test_acc_num\n",
    "            dataset_init = self.test_dataset_init\n",
    "        self.sess.run(dataset_init)\n",
    "        while True:\n",
    "            try:\n",
    "                _angles1, _angles2, _acc_num = self.sess.run([angles1, angles2, acc_num])\n",
    "                _angles1 = _angles1[_angles1 > 0]\n",
    "                _angles2 = _angles2[_angles2 > 0]\n",
    "                com_angles1.extend(_angles1)\n",
    "                com_angles2.extend(_angles2)\n",
    "                com_acc, com_num = com_acc + _acc_num, com_num + _angles1.size\n",
    "                print(f'\\r{cate}: com_acc: {com_acc / com_num:.3%} com_num: {com_num}...', end='')\n",
    "            except:\n",
    "                break\n",
    "        com_acc /= com_num\n",
    "        print(f'\\n{cate}: num: {com_num} acc: {com_acc:.3%} '\n",
    "              f'mean_angles1: {np.mean(com_angles1):.3f} mean_angles2: {np.mean(com_angles2):.3f}')\n",
    "\n",
    "        result_dir = f'../record/result/{default.restore_version[0]}'\n",
    "        self.check_dir(result_dir)\n",
    "\n",
    "        np.save(os.path.join(result_dir, f'{cate}_acc'), com_acc)\n",
    "        np.save(os.path.join(result_dir, f'{cate}_angles1'), com_angles1)\n",
    "        np.save(os.path.join(result_dir, f'{cate}_angles2'), com_angles2)\n",
    "\n",
    "        # 画图\n",
    "        save_path = os.path.join(result_dir, f'{cate}_angle_distribution.png')\n",
    "        histplot_angles([com_angles1, com_angles2], ['angles1', 'angles2'],\n",
    "                        title=f'{cate} angle distribution', show=True, save_path=save_path)\n",
    "\n",
    "        return com_acc, com_angles1, com_angles2\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "\n",
    "    def check_dir(self, fdir):\n",
    "        if not os.path.isdir(fdir):\n",
    "            os.makedirs(fdir)\n",
    "\n",
    "    def get_confusion_matrix(self, plot=False):\n",
    "\n",
    "        self._get_confusion_matrix('train', plot)\n",
    "        self._get_confusion_matrix('test', plot)\n",
    "\n",
    "    def _get_confusion_matrix(self, cate='train', plot=True):\n",
    "        com_num = 0\n",
    "        cum_labels, cum_predict = [], []\n",
    "        if cate == 'train':\n",
    "            labels, predict = self.train_labels, self.predict\n",
    "            ds_init = self.train_dataset_init\n",
    "        else:\n",
    "            labels, predict = self.test_labels, self.test_predict\n",
    "            ds_init = self.test_dataset_init\n",
    "        # 混淆矩阵 [预测类别，实际类别]=模型预测数目\n",
    "        confusion_matrix = np.zeros(shape=[config.num_cls, config.num_cls])\n",
    "        self.sess.run(ds_init)\n",
    "        while True:\n",
    "            try:\n",
    "                _labels, _predict = self.sess.run([labels, predict])\n",
    "                com_num += _labels.size\n",
    "                cum_labels.extend(_labels)\n",
    "                cum_predict.extend(_predict)\n",
    "                print(f'\\r{cate}: com_num: {com_num}...', end='')\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        lp = list(zip(cum_labels, cum_predict))\n",
    "        rcn = np.array([[i[0], i[1], lp.count(i)] for i in set(zip(cum_labels, cum_predict))])\n",
    "        confusion_matrix[rcn[:, 0], rcn[:, 1]] += rcn[:, 2]\n",
    "\n",
    "\n",
    "        plt.figure(figsize=[10, 10])\n",
    "        sns.heatmap(confusion_matrix)\n",
    "        plt.title(f'{cate} confusion_matrix')\n",
    "        plt.xlim([-0.5, config.num_cls + 0.5])\n",
    "        plt.ylim([-0.5, config.num_cls + 0.5])\n",
    "        # plt.xticks(np.arange(0.5, config.num_cls), range(config.num_cls))\n",
    "        # plt.yticks(np.arange(0.5, config.num_cls), range(config.num_cls))\n",
    "\n",
    "        result_dir = f'../record/result/{default.restore_version[0]}'\n",
    "        self.check_dir(result_dir)\n",
    "        np.save(os.path.join(result_dir, f'{cate}_confusion_matrix'), confusion_matrix)\n",
    "        plt.savefig(os.path.join(result_dir, f'{cate}_confusion_matrix.png'))\n",
    "        if plot: plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T15:50:18.562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\TEST\\ChangeFace\\recognition\\arcface\\data_generator.py:149: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\TEST\\ChangeFace\\recognition\\arcface\\data_generator.py:150: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-03fd442eaee0>:29: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "SUCCEED: make train dataset from f.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From E:\\TEST\\ChangeFace\\recognition\\arcface\\build_tensors.py:63: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\TEST\\ChangeFace\\recognition\\backbones\\darknet.py:35: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348EE8F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348EE8F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348EE8F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348EE8F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From E:\\TEST\\ChangeFace\\recognition\\backbones\\darknet.py:36: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E348EE8F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E348EE8F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E348EE8F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E348EE8F28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FEC438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FEC438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FEC438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FEC438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E349003A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E349003A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E349003A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x000001E349003A58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FD7A90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001E348FD7A90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T15:50:20.079Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.get_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-03T15:50:20.462Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
